---
title: 'Open vs. closed innovation: using online network data to measure innovation'
author: "Benjamin Snow and Oliver Bott"
date: "14 November 2014"
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
  html_document:
    fig_caption: yes
    number_sections: no
bibliography:
- Packages.bib
- Main.bib
---

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# Set working directory. Change as needed
setwd('C:/Users/a6p/Desktop/Uni 2014/E1161 - Collaborative Research/GitHub Clone/Assignment3/Assignment3/')

# Load packages and create BibTeX file
# Note: must have repmis, rsdmx, httr, dplyr and rjson packages installed
PackagesUsed <- c("ggplot2", "repmis", "rsdmx", "httr", "dplyr", "rjson", "stargazer", "knitr")

# Load PackagesUsed and create .bib BibTeX file
repmis::LoadandCite(PackagesUsed, file = "Packages.bib", install = FALSE)
```

# Background

This research project examines the potential benefit of using open knowledge data in the form of collaborative online network data as an innovation indicator. By doing so, this work critically assesses current innovation indicators, namely patent data, in the hope of offering new alternatives for measuring and understanding innovation. The stated research question is:  *To what extent can open innovation network data add to the measurement of innovation performance?*

For the full examination of the previous literature on the subject and reasoning for the purpose, motives, and plan for this study, please see the [Research Proposal](https://github.com/benjaminsnow/Collaborative-Research-Proposal-Assignment-Two-).  This contribution focuses specifically on outlining the data gathering, data cleaning, and merging process. It will also examine the constructed dataset using basic descriptive statistics, as well as run preliminary inferential statistical models, offering explanation and context throughout the process. Finally, steps to improve the analysis for the final version will be given.

# Data Gathering

To examine open network data against patent data, this study relies on two data key sources and uses the statistical tool R [@CiteR] for the data analysis. 

The first data set was obtained by using the Application Programming Interface (API) data for open networks. To examine open data innovation, data is obtained from the the git repository web-based hosting service GitHub[^GIT]. The R [@CiteR] packages httr @R-httr, dplyr @R-dplyr and rjson @R-rjson allow for compiling data on the follower counts and locations associated with different users and reponsitories.

As an indicator of closed innovation we use city-level patent registration data from the Organization for Economic Co-operation and Development[^OECD]. We use PCT patent applications per 10,000 inhabitants. From the same database, we also use GDP per capita data and environmental data, as other variables which could prove significant in explaining differences in innovation. From the same OECD database: GDP per capita, pollution levels, greenspace, and employment (as share of national employment) are taken for the relevant cities which github and patent data are obtained for. These other variables are inclued in the analysis as they could prove significant in explaining differences in innovation. The R [@CiteR] package rsdmx [@R-rsdmx] is necessary for obtaining the OECD dataset.

All data obtained via the GitHub API and OECD database can be linked to individual cities, allowing for an analysis on the regional level. The code used for gathering and cleaning the data can be accessed via this [link](https://github.com/oliverbott/Assignment3/blob/master/Data_Gathering.R).


```{r, include=FALSE}
# Load Dataset.csv from repository
library(RCurl)

# Set SSL certs globally
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))

x <- getURL('https://raw.githubusercontent.com/oliverbott/Assignment3/master/Dataset.csv')
dataset <- read.csv(text = x)

# Clean dataset
dataset$X <- NULL

# Turn follower numbers to per 10.000 from 500.000
dataset$nofollowing <- dataset$nofollowing/50
dataset$medfollowing <- dataset$medfollowing/50
dataset$hifollowing <- dataset$hifollowing/50

# To do log of nofollowing delete Kofu and Numazu, rows 62 and 90
dataset[-c(62, 90), ]
dataset <- dataset[-c(62, 90), ]

# Further, to do log of medfollowing and hifollowing also delete these rows without followers
dataset[-c(39, 45, 46, 59, 62, 73, 80, 114, 118, 119), ]
dataset <- dataset[-c(39, 45, 46, 59, 62, 73, 80, 114, 118, 119), ]

```

# Data Sources

Table 1 depicts the various variables used in the study. For a more in depth discussion of each variable, its year, its limitations and the reasoning and justification for selection to this study as an appropriate explanatory variable or proxy, please see ( Appendix ).

```{r, echo=FALSE, results='asis'}
library(knitr)

# Create table with info on variables
Variables <- c('Patents', 'GDP', 'Population', 'Greenspace', 'Employment', 'Pollution', 'No Following', '1-24 Following', '>25 Following')
Year <- c('2008', '2008','2008','2008','2008','2005', '2014', '2014', '2014')
Source <- c('OECD', 'OECD', 'OECD', 'OECD', 'OECD', 'OECD', 'API', 'API','API')

# Combine
limtab <- data.frame(Variables, Year, Source)

knitr::kable(limtab)
```

# Prelimianary Descriptive Statistical Analysis

A first examination of the distribution of each variable show distributions which reflect a .....  An examination of the distribution of both the patent applications and github users in each city are taken to examine if a similar distribution can be seen in cities when normalizing for population size.  A similar distribution would indicate ... (Olli, question here, if its examining when it is only no following, this isnt giving us total user numbers, just user numbers of those who dont have any following, right?)


```{r, echo=FALSE, results='asis'}

# Descriptive statistics

# summary(dataset[,2:10])
# knitr::kable(summary(dataset[,2:10])


# hist(dataset$Patents,
#      main = 'PCT applications',
#      xlab = 'PCT patent applications per 10,000 inhabitants')

# hist(dataset$nofollowing,
#      main = 'PCT applications',
#      xlab = 'PCT patent applications per 10,000 inhabitants')

```

Next, the car package @R-car is used to examine the relationship, distribution, and normality of all variables included in the model, to understand which regression model would be most appropriate.  Taking into account the clumped distribution of many variables, taking the log regression of several variables when regressing is attempted, to see if this brings about a more normal distribution.


```{r, echo=FALSE, results='asis'}
require("car")

#plot(dataset$Patents,dataset$Followers)
#plot(dataset[,3,7])


car::scatterplotMatrix(dataset[,2:10])
```

# Inferential Statistics

This study plans to use an ordinary least squares (OLS) model to examine the relationship between patent and highly followed open data sources. The high level of significance between these two variables, rather than demonstrating that one is acting on the other, show that some other 'spur of innovation' is acting on both, but does endorse the implicit hypothesis of the study that open data sources do seem to show innovation in a similar but perhaps distinct manner to patent data.  This found relationships offers a glimps into the 'throughput' of innovation rather than the 'output' which patent data reflects.  However, this is exceptionally early analysis and will need to be examined further.

Now that a relationship between patent and follower data has been shown, further inferential statistical analysis attempts to find the common predictor or cause of innovation in both patent and open data is necessary.  This is done by running identical Ordinary Least Squares regressions, using the the log of both patent and highly followed github users as the dependant variables, and the log of each of the previously mentioned independant variables (GDP, Population, Greenspace, Employment, and Pollution), to examine if any of these variables prove significantly (and presumably, similarly) correlated to our dependant variables. 

This process has allowed us first directly compare our previously established (patent) and newly hypothesized (open - github) measures of innovation. After comparing directly, attempting to find how they differently reflect innovation, as well as attempting to find the common cause of innovation for both the innovation throughput which is open data, and the innovation output which is patent data, is necessary.


```{r, echo=FALSE, results='asis'}

# Create patent models for stargazer regression output
library(stargazer)

P1 <- lm(log(Patents) ~ log(nofollowing), data = dataset)
P2 <- lm(log(Patents) ~ log(medfollowing), data = dataset)
P3 <- lm(log(Patents) ~ log(hifollowing), data = dataset)
P4 <- lm(log(Patents) ~ log(hifollowing) + log(GDP) + log(Population) + log(Greenspace) + log(Employment) + log(Pollution), data = dataset)

labelsP <- c('(Intercept)', 'No Following', '1-24 Following', '>25 Following', 'GDP', 'Population', 'Greenspace', 'Employment', 'Pollution')

stargazer::stargazer(P1, P2, P3, P4, covariate.labels = labelsP,
  title = 'Regression Estimates of Patent Activity',
  digits = 2, type ='latex', header=FALSE)
```


```{r, echo=FALSE, results='asis'}

# Create follower model for stargazer regression output

F1 <- lm(log(hifollowing) ~ log(Patents), data = dataset)
F2 <- lm(log(hifollowing) ~ log(Patents) + log(GDP) + log(Population) + log(Greenspace) + log(Employment) + log(Pollution), data = dataset)

labelsF <- c('(Intercept)', 'Patents', 'GDP', 'Population', 'Greenspace', 'Employment', 'Pollution')

stargazer::stargazer(F1, F2, covariate.labels = labelsF,
  title = 'Regression Estimates of Follower Numbers',
  digits = 2, type ='latex', header=FALSE)
```

[^OECD]: Online accessible on http://stats.oecd.org.
[^GIT]: Online accessilbe on https://github.com/.

# References




